{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_divide_ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67yVeo0A0W37"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7giqK6SQyXx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-4pejXlCeOw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzY9nDlMCeOx"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYU_9VwtCeOy"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKfeDgiaCeOy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMx_luGlCeOy"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "from matplotlib import pyplot\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import array\n",
        "from numpy import dstack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9pc_r1gCeOz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import max_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVR\n",
        "import os\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EhmiP6UCnQQ",
        "outputId": "6f88c4b7-6f92-41ff-da04-e7e1cf595d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn84x4j5CeOz"
      },
      "outputs": [],
      "source": [
        "def norm(x):\n",
        "    return (x - train_stats['mean']) / train_stats['std']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L4CfalfTlt9"
      },
      "outputs": [],
      "source": [
        "def parse(x):\n",
        "    return datetime.strptime(x, '%Y %m %d %H')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jtXO-s40lPb"
      },
      "outputs": [],
      "source": [
        "def tie_dataset(feature, label, timestep = 24, want_period = 1):\n",
        "    feature_list = []\n",
        "    label_list = []\n",
        "\n",
        "    for i in range(timestep, len(feature)-want_period):\n",
        "        feature_list.append(feature[i-timestep:i])\n",
        "        label_list.append(label[i:i+want_period]) \n",
        "        #label_list.append(label[i])\n",
        "    return np.array(feature_list), np.array(label_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_data(dataset, step = 1, length = 12000):\n",
        "    data_list = []\n",
        "\n",
        "    for i in range(0, len(dataset) - length, step):\n",
        "        data_list.append(dataset.iloc[i:i+length])\n",
        "\n",
        "    return data_list\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "c8lUfbC9hPhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHEuo9MMCeO1"
      },
      "outputs": [],
      "source": [
        "def generate_model_lstm(trainX, trainy):\n",
        "    \n",
        "    model = Sequential()\n",
        "    # model.add(LSTM(48, activation='tanh', return_sequences=True))\n",
        "    model.add(LSTM(128, activation='tanh'))\n",
        "    model.add(Dense(1))\n",
        "   \n",
        "    model.compile(loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae', 'mse'])\n",
        "    \n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "    filename = os.path.join('/content/gdrive/My Drive/Colab Notebooks', 'generation_data_lstm_checkpoint.h5')\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "    model.fit(trainX, trainy, epochs=200, validation_split = 0.2, verbose=0,\n",
        "                 callbacks=[early_stop, checkpoint]) \n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_model_cnn(trainX, trainy):   \n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=4, kernel_size= 1, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2)) # 데이터 크기 1/2로 줄여줌\n",
        "    #model.add(Flatten()) # 다차원 배열을 1차원으로 바꿔줌\n",
        "\n",
        "    #model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "    model.add(LSTM(64, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae', 'mse'])\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    filename = os.path.join('/content/gdrive/My Drive/Colab Notebooks', 'generation_cnnlsmt_checkpoint.h5')\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "    model.fit(trainX, trainy, epochs=100, validation_split = 0.2, verbose=0,  \n",
        "                    callbacks=[early_stop, checkpoint])\n",
        "\n",
        "    return model \n",
        "\n",
        "\n",
        "\n",
        " \n",
        "def generate_model_gru(trainX, trainy):   \n",
        "\n",
        "    model = Sequential()\n",
        "    #model.add(GRU(64, activation='tanh', return_sequences=True))\n",
        "    model.add(GRU(64, activation='tanh'))\n",
        "    model.add(Dense(1))\n",
        "   \n",
        "    model.compile(loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae', 'mse'])\n",
        "    \n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    filename = os.path.join('/content/gdrive/My Drive/Colab Notebooks', 'generation_gru_checkpoint.h5')\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "    model.fit(trainX, trainy, epochs=100, validation_split = 0.2, verbose=0,  \n",
        "                    callbacks=[early_stop, checkpoint])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def generate_model_mlp(trainX, trainy):   \n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='tanh'))\n",
        "    model.add(Dense(64, activation='tanh'))\n",
        "    model.add(Dense(1))\n",
        "   \n",
        "    model.compile(loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae', 'mse'])\n",
        "    \n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    filename = os.path.join('/content/gdrive/My Drive/Colab Notebooks', 'generation_mlp_checkpoint.h5')\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "    model.fit(trainX, trainy, epochs=100, validation_split = 0.2, verbose=0,  \n",
        "                    callbacks=[early_stop, checkpoint])\n",
        "\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def generate_meta_model(trainX, trainy):\n",
        "\n",
        "    model = Sequential()\n",
        "  \n",
        "    #model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "    model.add(LSTM(64, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae', 'mse'])\n",
        "    \n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "    filename = os.path.join('/content/gdrive/My Drive/Colab Notebooks', 'generation_lstm_checkpoint.h5')\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "    model.fit(trainX, trainy, epochs=300, validation_split = 0.2, verbose=0,  \n",
        "                    callbacks=[early_stop, checkpoint])\n",
        "    \n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF6Uw4dNk7hx"
      },
      "outputs": [],
      "source": [
        "def load_all_models(n_models):\n",
        "\tall_models = list()\n",
        "\tfor i in range(n_models):\n",
        "\t\t# define filename for this ensemble\n",
        "\t\tfilename = '/content/gdrive/My Drive/Colab Notebooks/model_' + str(i + 1) + '.h5'\n",
        "\t\t# load model from file\n",
        "\t\tmodel = tf.keras.models.load_model(filename)\n",
        "\t\t# add to list of members\n",
        "\t\tall_models.append(model)\n",
        "\t\tprint('>loaded %s' % filename)\n",
        "\treturn all_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAFouvyxCeO1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.path.join('/content/gdrive/My Drive/Colab Notebooks', 'train_hourly.csv'), encoding='utf8')\n",
        "df_forecast = pd.read_csv(os.path.join('/content/gdrive/My Drive/Colab Notebooks', 'test_hourly.csv'), encoding='cp949')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_train = pd.concat([df, df_forecast], axis=0)\n",
        "all_train = all_train.reset_index()\n",
        "all_train = all_train.drop(['index', 'year', 'month', 'day', 'hour'], axis=1)\n",
        "all_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OqvBUBKEzJ18",
        "outputId": "5efea047-005f-4bc9-80a1-34d1522847bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1028857c-390e-42f7-9cd1-be06448ddb3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>dew_point</th>\n",
              "      <th>sol_rad</th>\n",
              "      <th>cloud</th>\n",
              "      <th>pow_gen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.3</td>\n",
              "      <td>77</td>\n",
              "      <td>0.6</td>\n",
              "      <td>100.000</td>\n",
              "      <td>0</td>\n",
              "      <td>140.631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.3</td>\n",
              "      <td>80</td>\n",
              "      <td>1.1</td>\n",
              "      <td>72.222</td>\n",
              "      <td>0</td>\n",
              "      <td>85.793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.8</td>\n",
              "      <td>80</td>\n",
              "      <td>0.6</td>\n",
              "      <td>55.556</td>\n",
              "      <td>0</td>\n",
              "      <td>32.590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.4</td>\n",
              "      <td>80</td>\n",
              "      <td>0.2</td>\n",
              "      <td>13.889</td>\n",
              "      <td>0</td>\n",
              "      <td>0.154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>70</td>\n",
              "      <td>-4.8</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>7.275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16568</th>\n",
              "      <td>15.0</td>\n",
              "      <td>24</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>609.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1079.446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16569</th>\n",
              "      <td>16.0</td>\n",
              "      <td>23</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>563.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1018.955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16570</th>\n",
              "      <td>16.0</td>\n",
              "      <td>24</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>468.000</td>\n",
              "      <td>0</td>\n",
              "      <td>852.790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16571</th>\n",
              "      <td>14.0</td>\n",
              "      <td>29</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>329.000</td>\n",
              "      <td>0</td>\n",
              "      <td>425.755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16572</th>\n",
              "      <td>12.0</td>\n",
              "      <td>41</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>157.000</td>\n",
              "      <td>0</td>\n",
              "      <td>183.764</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16573 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1028857c-390e-42f7-9cd1-be06448ddb3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1028857c-390e-42f7-9cd1-be06448ddb3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1028857c-390e-42f7-9cd1-be06448ddb3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       temperature  humidity  dew_point  sol_rad  cloud   pow_gen\n",
              "0              4.3        77        0.6  100.000      0   140.631\n",
              "1              4.3        80        1.1   72.222      0    85.793\n",
              "2              3.8        80        0.6   55.556      0    32.590\n",
              "3              3.4        80        0.2   13.889      0     0.154\n",
              "4              0.0        70       -4.8    0.000      0     7.275\n",
              "...            ...       ...        ...      ...    ...       ...\n",
              "16568         15.0        24       -5.0  609.000      0  1079.446\n",
              "16569         16.0        23       -6.0  563.000      0  1018.955\n",
              "16570         16.0        24       -5.0  468.000      0   852.790\n",
              "16571         14.0        29       -4.0  329.000      0   425.755\n",
              "16572         12.0        41       -1.0  157.000      0   183.764\n",
              "\n",
              "[16573 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = 14000\n",
        "step = int((len(all_train) - length) / 4)\n",
        "data_list = divide_data(all_train, step, length)\n",
        "data_list"
      ],
      "metadata": {
        "id": "ntPcL4dqDwKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ad9ad6-39a9-489d-9781-8eaa880cadf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[       temperature  humidity  dew_point  sol_rad  cloud   pow_gen\n",
              " 0              4.3        77        0.6  100.000      0   140.631\n",
              " 1              4.3        80        1.1   72.222      0    85.793\n",
              " 2              3.8        80        0.6   55.556      0    32.590\n",
              " 3              3.4        80        0.2   13.889      0     0.154\n",
              " 4              0.0        70       -4.8    0.000      0     7.275\n",
              " ...            ...       ...        ...      ...    ...       ...\n",
              " 13995         32.9        41       17.8  675.000      8  1020.833\n",
              " 13996         33.0        41       17.9  686.111      6   873.120\n",
              " 13997         31.5        47       18.8  530.556      3   693.494\n",
              " 13998         29.7        52       18.7  233.333      6   420.027\n",
              " 13999         21.2        96       20.5   19.444     10   297.109\n",
              " \n",
              " [14000 rows x 6 columns],\n",
              "        temperature  humidity  dew_point  sol_rad  cloud   pow_gen\n",
              " 643           -5.9        46      -15.6   19.444      0   139.903\n",
              " 644           -4.5        43      -15.2  152.778      0   513.809\n",
              " 645           -3.3        41      -14.7  377.778      0   806.067\n",
              " 646           -1.7        37      -14.5  530.556      0  1013.080\n",
              " 647           -0.6        36      -13.8  625.000      0  1109.466\n",
              " ...            ...       ...        ...      ...    ...       ...\n",
              " 14638         23.9        99       23.7   13.889     10    74.978\n",
              " 14639         24.1        99       23.9   13.889     10   225.395\n",
              " 14640         24.6        99       24.4   50.000     10   345.742\n",
              " 14641         24.7        99       24.5   69.444     10   209.302\n",
              " 14642         23.1        98       22.7   63.889     10   123.895\n",
              " \n",
              " [14000 rows x 6 columns],\n",
              "        temperature  humidity  dew_point  sol_rad  cloud  pow_gen\n",
              " 1286          15.8        39        1.8  930.556      0  707.391\n",
              " 1287          15.3        49        4.6  852.778      0  687.124\n",
              " 1288          14.9        45        3.0  744.444      0  443.521\n",
              " 1289          14.4        53        4.9  547.222      0  283.375\n",
              " 1290          13.2        59        5.3  377.778      0  230.344\n",
              " ...            ...       ...        ...      ...    ...      ...\n",
              " 15281         18.5        35        2.7  683.333      0  236.880\n",
              " 15282         19.5        32        2.3  636.111      0  447.159\n",
              " 15283         19.9        33        3.1  538.889      0  158.638\n",
              " 15284         19.6        37        4.4  388.889      0   74.940\n",
              " 15285         18.7        40        4.8  208.333      0    7.063\n",
              " \n",
              " [14000 rows x 6 columns],\n",
              "        temperature  humidity  dew_point  sol_rad  cloud  pow_gen\n",
              " 1929          19.2        64       12.2  166.667      0   60.330\n",
              " 1930          21.1        57       12.2  363.889      0   56.456\n",
              " 1931          22.9        51       12.2  563.889      0   67.727\n",
              " 1932          23.3        49       11.9  750.000      0  231.184\n",
              " 1933          24.2        45       11.5  875.000      0  206.223\n",
              " ...            ...       ...        ...      ...    ...      ...\n",
              " 15924          2.9        39       -9.7    0.000      8   29.951\n",
              " 15925          3.6        41       -8.4    2.778      0  152.979\n",
              " 15926          5.0        34       -9.5  116.667      6  415.634\n",
              " 15927          5.8        32       -9.6  286.111      3  605.552\n",
              " 15928          6.7        30       -9.6  408.333      3  666.512\n",
              " \n",
              " [14000 rows x 6 columns],\n",
              "        temperature  humidity  dew_point  sol_rad  cloud   pow_gen\n",
              " 2572          33.0        60       24.1  650.000      0  1202.983\n",
              " 2573          32.1        66       24.9  280.556      0  1195.509\n",
              " 2574          32.0        67       25.0  313.889      0  1118.160\n",
              " 2575          33.3        64       25.5  583.333      0   962.576\n",
              " 2576          33.3        64       25.5  616.667      0   765.289\n",
              " ...            ...       ...        ...      ...    ...       ...\n",
              " 16567         14.0        26       -5.0  602.000      0   885.809\n",
              " 16568         15.0        24       -5.0  609.000      0  1079.446\n",
              " 16569         16.0        23       -6.0  563.000      0  1018.955\n",
              " 16570         16.0        24       -5.0  468.000      0   852.790\n",
              " 16571         14.0        29       -4.0  329.000      0   425.755\n",
              " \n",
              " [14000 rows x 6 columns]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_stats = all_train.describe()\n",
        "train_stats.pop(\"pow_gen\")\n",
        "train_stats = train_stats.transpose()"
      ],
      "metadata": {
        "id": "IzZ7n7EAYyWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EKBJC_eCeO3"
      },
      "outputs": [],
      "source": [
        "#Split dataset into training and testing set\n",
        "train_final_set = []\n",
        "test_final_set = []\n",
        "target_set = []\n",
        "test_target_set = []\n",
        "\n",
        "for i in range(0,len(data_list)):\n",
        "\n",
        "    train_size = int(len(data_list[i])*0.7)\n",
        "    test_size = int(len(data_list[i])*0.3)\n",
        " \n",
        "# train_dataset = df[:train_size, ['month', 'day', 'hour', 'temperature', 'humidity', 'dew_point', 'sol_rad', 'cloud', 'pow_gen']]\n",
        "    train_dataset = data_list[i].iloc[:train_size]\n",
        "    test_dataset = data_list[i].iloc[train_size : train_size + test_size]                     #시 발전량 기온 습도 이슬점온도 일사량 전운량\n",
        "# test_dataset = df_forecast[['month', 'day', 'hour', 'temperature', 'humidity', 'dew_point', 'sol_rad', 'cloud', 'pow_gen']]\n",
        "\n",
        "    train_labels = train_dataset.pop('pow_gen')\n",
        "    test_labels = test_dataset.pop('pow_gen')\n",
        "\n",
        "    normed_train_data = norm(train_dataset)\n",
        "    normed_test_data = norm(test_dataset)\n",
        "    \n",
        "    train_final= normed_train_data.values\n",
        "    test_final = normed_test_data.values\n",
        "    target=train_labels.values\n",
        "    test_target=test_labels.values\n",
        "    \n",
        "    train_final_set.append(train_final)\n",
        "    test_final_set.append(test_final)\n",
        "    target_set.append(target)\n",
        "    test_target_set.append(test_target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainx, trainla = tie_dataset(train_final_set[0], target_set)\n",
        "trainx.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAg4LY1TowkS",
        "outputId": "78ba4a5e-e072-4162-a0bb-dedf358ec326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9775, 24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "members = list()\n",
        "trainx_set = list()\n",
        "trainy_set = list()\n",
        "testy_set = list()\n",
        "testx_set = list()\n",
        "\n",
        "for i in range(0, len(data_list)):\n",
        "\n",
        "    # trainX, trainy = tie_dataset(pca_train, target)\n",
        "    # testX, testy = tie_dataset(pca_test, test_target)\n",
        "\n",
        "    trainX, trainy = tie_dataset(train_final_set[i], target_set[i])\n",
        "    testX, testy = tie_dataset(test_final_set[i], test_target_set[i])\n",
        "    \n",
        "    trainx_set.append(trainX)\n",
        "    trainy_set.append(trainy)\n",
        "    testx_set.append(testX)\n",
        "    testy_set.append(testy)\n",
        "\n",
        "\n",
        "for i in range(0, len(data_list)):\n",
        "    model = generate_model_lstm(trainx_set[i], trainy_set[i])\n",
        "    members.append(model)\n",
        "   "
      ],
      "metadata": {
        "id": "EQJm5Y98Xlr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd077df-b7f2-493c-d7c3-e70de6cd8166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 408008.56250, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00002: val_loss improved from 408008.56250 to 378392.62500, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 378392.62500 to 351691.75000, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 351691.75000 to 327750.84375, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 327750.84375 to 306027.62500, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 306027.62500 to 286383.96875, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 286383.96875 to 268708.09375, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 268708.09375 to 252762.76562, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 252762.76562 to 238450.95312, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 238450.95312 to 225689.14062, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 225689.14062 to 214340.43750, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 214340.43750 to 204367.95312, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00013: val_loss improved from 204367.95312 to 195549.34375, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00014: val_loss improved from 195549.34375 to 187960.78125, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 187960.78125 to 181458.39062, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n",
            "\n",
            "Epoch 00016: val_loss improved from 181458.39062 to 175935.90625, saving model to /content/gdrive/My Drive/Colab Notebooks/generation_data_lstm_checkpoint.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "members"
      ],
      "metadata": {
        "id": "vAwgmIZfGN8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93YuVXwifgDL"
      },
      "outputs": [],
      "source": [
        "n_splits = len(data_list)\n",
        "for i in range(n_splits):\n",
        "\t#model = generate_model_lstm(trainX, trainy)\n",
        "\tfilename = '/content/gdrive/My Drive/Colab Notebooks/model_' + str(i + 1) + '.h5'\n",
        "\tmembers[i].save(filename)\n",
        "\tprint('>Saved %s' % filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md0zJAiAfgFQ"
      },
      "outputs": [],
      "source": [
        "load_members = list()\n",
        "\n",
        "n_splits = len(data_list)\n",
        "load_members = load_all_models(n_splits)\n",
        "print('Loaded %d models' % len(load_members))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_set = list()\n",
        "\n",
        "for i in range(n_splits):\n",
        "    predict_set.append(load_members[i].predict(testx_set[4]))"
      ],
      "metadata": {
        "id": "dMAi2EhmTIJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_set = list()\n",
        "\n",
        "for i in range(n_splits):\n",
        "    mse = mean_squared_error(testy_set[4], predict_set[i], squared=False)\n",
        "    mse_set.append(mse)"
      ],
      "metadata": {
        "id": "zjp2W1-DjrCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_set"
      ],
      "metadata": {
        "id": "of8u9dPojrEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update({\n",
        "    'font.family': 'Times New Roman',\n",
        "    'font.size': 18,\n",
        "    'figure.figsize': (12, 5),\n",
        "    'axes.grid' : True, 'axes.grid.axis': 'y'\n",
        "})"
      ],
      "metadata": {
        "id": "BFS2E20LRduS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "single_mse = list()\n",
        "ensemble_mse = list()\n",
        "\n",
        "for i in range(1, n_splits+1):\n",
        "  \n",
        "    subset = load_members[:i]\n",
        "    yhats = [model.predict(testx_set[4]) for model in subset]\n",
        "    yhats = array(yhats)\n",
        "    yhats[yhats<0] = 0\n",
        "    averaged = np.average(yhats, axis=0)\n",
        "    ensemble = mean_squared_error(testy_set[4],averaged,squared=False)\n",
        "\n",
        "    *_, y1 = [load_members[i-1].predict(testx_set[4])]\n",
        "    y1[y1<0] = 0\n",
        "    single =  mean_squared_error(testy_set[4],y1,squared=False)\n",
        "\n",
        "        #X_test_cnn = X_test.reshape(X_test.shape[0], 4,1,1)\n",
        "        # *_, y2 = [members_cnn[i-1].predict(X_test)]\n",
        "        # y2[y2<0] = 0\n",
        "        # cnn_lstm = mean_squared_error(Y_test, y2, squared=False) \n",
        "\n",
        "        # *_, y3 = [members_gru[i-1].predict(X_test)]\n",
        "        # y3[y3<0] = 0\n",
        "        # single_gru = mean_squared_error(Y_test, y3, squared=False) \n",
        "    \n",
        "        # *_, y4 = [members_mlp[i-1].predict(X_test)]\n",
        "        # y4[y4<0] = 0\n",
        "        # single_mlp = mean_squared_error(Y_test, y4, squared=False) \n",
        "\n",
        "        #print('> %d: LSTM=%.3f, cnn_lstm=%.3f, ensemble=%.3f' % (i, single_lstm, cnn_lstm, ensemble))\n",
        "    print('> %d: Single=%.3f, Ensemble=%.3f' % (i, single, ensemble))\n",
        "    single_mse.append(single)\n",
        "    # cnn_mse.append(cnn_lstm)\n",
        "    ensemble_mse.append(ensemble) \n",
        "    \n",
        "    # gru_mse.append(single_gru)\n",
        "    # mlp_mse.append(single_mlp)"
      ],
      "metadata": {
        "id": "-aqD1Cf3Rdwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot score vs number of ensemble members\n",
        "print('RMSE Single Learners %.3f (%.3f)' % (mean(single_mse), std(single_mse)))\n",
        "#print('RMSE Cnn_lstm Learners %.3f (%.3f)' % (mean(cnn_mse), std(cnn_mse)))\n",
        "print('RMSE Ensemble Learners %.3f (%.3f)' % (mean(ensemble_mse), std(ensemble_mse)))\n",
        "#print('RMSE GRU Learners %.3f (%.3f)' % (mean(gru_mse), std(gru_mse)))\n",
        "\n",
        "x_axis = [i for i in range(1, n_splits+1)]\n",
        "pyplot.plot(x_axis, single_mse, marker='o', label='Single Model')\n",
        "#pyplot.plot(x_axis, cnn_mse, marker='o', label='LSTM + CNN')\n",
        "pyplot.plot(x_axis, ensemble_mse, marker='o', label='Ensemble Model (Ours)')\n",
        "#pyplot.plot(x_axis, gru_mse, marker='o', label='GRU')\n",
        "#pyplot.plot(x_axis, gru_mse, marker='o', label='GRU')\n",
        "plt.title(\"Root Mean Squared Error: Single Learner vs Ensemble Learners (Bagging)\")\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "B4flFf5iRd0A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}